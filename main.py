"""\nDigital Being â€” Entry Point\nStage 28-30: FINAL INTEGRATION - Advanced Multi-Agent + Memory + Self-Evolution (COMPLETE)\n+ HOT RELOADER: Live Python code reloading without restart! ðŸ”¥\n+ PHASE 3 MULTI-AGENT: Fully integrated 6-component system\n"""\n\nfrom __future__ import annotations\n\nimport asyncio\nimport json\nimport logging\nimport signal\nimport sys\nimport time\nfrom pathlib import Path\n\nimport yaml\n\nfrom core.attention_system import AttentionSystem\nfrom core.belief_system import BeliefSystem\nfrom core.contradiction_resolver import ContradictionResolver\nfrom core.curiosity_engine import CuriosityEngine\nfrom core.dream_mode import DreamMode\nfrom core.emotion_engine import EmotionEngine\nfrom core.event_bus import EventBus\nfrom core.file_monitor import FileMonitor\nfrom core.goal_persistence import GoalPersistence\n\n# Fault-Tolerant Architecture\nfrom core.fault_tolerant_heavy_tick import FaultTolerantHeavyTick\n\n# Goal Hierarchy & Tools & Learning\nfrom core.goal_integration import GoalOrientedBehavior\nfrom core.tools import ToolRegistry, initialize_default_tools\nfrom core.learning import LearningEngine, PatternGuidedPlanner\n\n# Advanced Cognitive Features\nfrom core.memory_consolidation import MemoryConsolidation\nfrom core.theory_of_mind import UserModel\nfrom core.proactive_behavior import ProactiveBehaviorEngine\nfrom core.meta_learning import MetaOptimizer\n\n# Stage 26 - Skill Library\nfrom core.skill_library import SkillLibrary\n\n# Stage 27-28 - Multi-Agent System (Phase 3)\nfrom core.multi_agent_integration import MultiAgentSystem, create_multi_agent_system\nfrom core.multi_agent import AgentRole\n\n# Stage 29 - Long-term Memory\nfrom core.memory.memory_consolidation import MemoryConsolidation as LongTermMemoryConsolidation\nfrom core.memory.semantic_memory import SemanticMemory\nfrom core.memory.memory_retrieval import MemoryRetrieval\n\n# Stage 30 - Self-Evolution (COMPLETE)\nfrom core.self_evolution import (\n    SelfEvolutionManager,\n    EvolutionMode,\n    ChangeType,\n    # Priority 1: Critical\n    LLMCodeAssistant,\n    SafetyValidator,\n    PerformanceMonitor,\n    AutoRollbackHandler,\n    # Priority 2: Advanced\n    DependencyAnalyzer,\n    PriorityQueue,\n    EvolutionRateLimiter,\n    CanaryDeployment,\n)\n\n# ðŸ”¥ HOT RELOADER - Live code changes!\nfrom core.hot_reloader import HotReloader\n\nfrom core.introspection_api import IntrospectionAPI\nfrom core.light_tick import LightTick\nfrom core.memory.episodic import EpisodicMemory\nfrom core.memory.vector_memory import VectorMemory\nfrom core.meta_cognition import MetaCognition\nfrom core.milestones import Milestones\nfrom core.narrative_engine import NarrativeEngine\nfrom core.ollama_client import OllamaClient\nfrom core.reflection_engine import ReflectionEngine\nfrom core.self_model import SelfModel\nfrom core.self_modification import SelfModificationEngine\nfrom core.shell_executor import ShellExecutor\nfrom core.social_layer import SocialLayer\nfrom core.strategy_engine import StrategyEngine\nfrom core.time_perception import TimePerception\nfrom core.value_engine import ValueEngine\nfrom core.world_model import WorldModel\n\nROOT_DIR      = Path(__file__).parent.resolve()\nCONFIG_PATH   = ROOT_DIR / \"config.yaml\"\nSEED_PATH     = ROOT_DIR / \"seed.yaml\"\n_MAX_DESC_LEN = 1000\n\ndef load_yaml(path: Path) -> dict:\n    if not path.exists():\n        raise FileNotFoundError(f\"Required file not found: {path}\")\n    with path.open(\"r\", encoding=\"utf-8\") as f:\n        return yaml.safe_load(f)\n\ndef setup_logging(cfg: dict) -> logging.Logger:\n    log_dir   = Path(cfg[\"logging\"][\"dir\"])\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_level = getattr(logging, cfg[\"logging\"].get(\"level\", \"INFO\").upper(), logging.INFO)\n    fmt       = \"%(asctime)s [%(levelname)s] %(name)s â€” %(message)s\"\n    datefmt   = \"%Y-%m-%d %H:%M:%S\"\n    logging.basicConfig(\n        level=log_level, format=fmt, datefmt=datefmt,\n        handlers=[\n            logging.StreamHandler(sys.stdout),\n            logging.FileHandler(log_dir / \"digital_being.log\", encoding=\"utf-8\"),\n        ],\n    )\n    a_handler = logging.FileHandler(log_dir / \"actions.log\", encoding=\"utf-8\")\n    a_handler.setFormatter(logging.Formatter(fmt, datefmt=datefmt))\n    logging.getLogger(\"digital_being.actions\").addHandler(a_handler)\n    return logging.getLogger(\"digital_being\")\n\ndef ensure_directories(cfg: dict) -> None:\n    dirs = [\n        Path(cfg[\"memory\"][\"episodic_db\"]).parent,\n        Path(cfg[\"memory\"][\"semantic_lance\"]).parent,\n        Path(cfg[\"logging\"][\"dir\"]),\n        Path(cfg[\"paths\"][\"state\"]).parent,\n        Path(cfg[\"paths\"][\"snapshots\"]),\n        Path(cfg[\"scores\"][\"drift\"][\"snapshot_dir\"]),\n        ROOT_DIR / \"memory\" / \"self_snapshots\",\n        ROOT_DIR / \"milestones\",\n        ROOT_DIR / \"sandbox\",\n        ROOT_DIR / \"data\",\n        ROOT_DIR / \"memory\" / \"multi_agent\",  # multi-agent storage\n        ROOT_DIR / \"memory\" / \"semantic\",     # semantic memory\n        ROOT_DIR / \"memory\" / \"self_evolution\",  # evolution storage\n    ]\n    for p in dirs:\n        p.mkdir(parents=True, exist_ok=True)\n    for key in (\"inbox\", \"outbox\"):\n        p = Path(cfg[\"paths\"][key])\n        if not p.exists():\n            p.touch()\n\ndef is_first_run(cfg: dict) -> bool:\n    return not Path(cfg[\"paths\"][\"state\"]).exists()\n\ndef bootstrap_from_seed(seed: dict, cfg: dict, logger: logging.Logger) -> None:\n    identity = seed.get(\"identity\", {})\n    state = {\n        \"name\":           identity.get(\"name\", \"Digital Being\"),\n        \"purpose\":        identity.get(\"purpose\", \"\"),\n        \"scores\":         seed.get(\"scores\", {}),\n        \"pending_tasks\":  seed.get(\"first_instructions\", []),\n        \"anchor_values\":  seed.get(\"anchor_values\", {}),\n        \"tick_count\":     0,\n        \"initialized_at\": time.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n    }\n    state_path = Path(cfg[\"paths\"][\"state\"])\n    state_path.parent.mkdir(parents=True, exist_ok=True)\n    with state_path.open(\"w\", encoding=\"utf-8\") as f:\n        json.dump(state, f, ensure_ascii=False, indent=2)\n    logger.info(f\"First run: state bootstrapped as '{state['name']}'.\")\n\ndef make_memory_handlers(mem: EpisodicMemory, logger: logging.Logger) -> dict:\n    async def on_user_message(data: dict) -> None:\n        text = data.get(\"text\", \"\")\n        logger.info(f\"[EVENT] user.message â†’ '{text[:120]}'\")\n        mem.add_episode(\"user.message\", text[:_MAX_DESC_LEN] or \"(empty)\", data={\"tick\": data.get(\"tick\")})\n    async def on_user_urgent(data: dict) -> None:\n        text = data.get(\"text\", \"\")\n        logger.warning(f\"[EVENT] user.urgent âš¡ â†’ '{text[:120]}'\")\n        mem.add_episode(\"urgent\", text[:_MAX_DESC_LEN] or \"(empty)\", data={\"tick\": data.get(\"tick\")})\n    async def on_file_changed(data: dict) -> None:\n        mem.add_episode(\"world.file_changed\", f\"File modified: {data.get('path','?')}\")