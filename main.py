"""\nDigital Being ‚Äî Entry Point\nStage 27.5: Multi-Agent Communication integrated with main system.\n"""\n\nfrom __future__ import annotations\n\nimport asyncio\nimport json\nimport logging\nimport signal\nimport sys\nimport time\nfrom pathlib import Path\n\nimport yaml\n\nfrom core.attention_system import AttentionSystem\nfrom core.belief_system import BeliefSystem\nfrom core.contradiction_resolver import ContradictionResolver\nfrom core.curiosity_engine import CuriosityEngine\nfrom core.dream_mode import DreamMode\nfrom core.emotion_engine import EmotionEngine\nfrom core.event_bus import EventBus\nfrom core.file_monitor import FileMonitor\nfrom core.goal_persistence import GoalPersistence\n\n# NEW: Fault-Tolerant Architecture\nfrom core.fault_tolerant_heavy_tick import FaultTolerantHeavyTick\n\n# NEW: Goal Hierarchy & Tools & Learning\nfrom core.goal_integration import GoalOrientedBehavior\nfrom core.tools import ToolRegistry, initialize_default_tools\nfrom core.learning import LearningEngine, PatternGuidedPlanner\n\n# NEW: Advanced Cognitive Features\nfrom core.memory_consolidation import MemoryConsolidation\nfrom core.theory_of_mind import UserModel\nfrom core.proactive_behavior import ProactiveBehaviorEngine\nfrom core.meta_learning import MetaOptimizer\n\n# NEW: Stage 26 - Skill Library\nfrom core.skill_library import SkillLibrary\n\n# NEW: Stage 27 - Multi-Agent Communication\nfrom core.multi_agent_coordinator import MultiAgentCoordinator\n\nfrom core.introspection_api import IntrospectionAPI\nfrom core.light_tick import LightTick\nfrom core.memory.episodic import EpisodicMemory\nfrom core.memory.vector_memory import VectorMemory\nfrom core.meta_cognition import MetaCognition\nfrom core.milestones import Milestones\nfrom core.narrative_engine import NarrativeEngine\nfrom core.ollama_client import OllamaClient\nfrom core.reflection_engine import ReflectionEngine\nfrom core.self_model import SelfModel\nfrom core.self_modification import SelfModificationEngine\nfrom core.shell_executor import ShellExecutor\nfrom core.social_layer import SocialLayer\nfrom core.strategy_engine import StrategyEngine\nfrom core.time_perception import TimePerception\nfrom core.value_engine import ValueEngine\nfrom core.world_model import WorldModel\n\nROOT_DIR      = Path(__file__).parent.resolve()\nCONFIG_PATH   = ROOT_DIR / "config.yaml"\nSEED_PATH     = ROOT_DIR / "seed.yaml"\n_MAX_DESC_LEN = 1000\n\ndef load_yaml(path: Path) -> dict:\n    if not path.exists():\n        raise FileNotFoundError(f"Required file not found: {path}")\n    with path.open("r", encoding="utf-8") as f:\n        return yaml.safe_load(f)\n\ndef setup_logging(cfg: dict) -> logging.Logger:\n    log_dir   = Path(cfg["logging"]["dir"])\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_level = getattr(logging, cfg["logging"].get("level", "INFO").upper(), logging.INFO)\n    fmt       = "%(asctime)s [%(levelname)s] %(name)s ‚Äî %(message)s"\n    datefmt   = "%Y-%m-%d %H:%M:%S"\n    logging.basicConfig(\n        level=log_level, format=fmt, datefmt=datefmt,\n        handlers=[\n            logging.StreamHandler(sys.stdout),\n            logging.FileHandler(log_dir / "digital_being.log", encoding="utf-8"),\n        ],\n    )\n    a_handler = logging.FileHandler(log_dir / "actions.log", encoding="utf-8")\n    a_handler.setFormatter(logging.Formatter(fmt, datefmt=datefmt))\n    logging.getLogger("digital_being.actions").addHandler(a_handler)\n    return logging.getLogger("digital_being")\n\ndef ensure_directories(cfg: dict) -> None:\n    dirs = [\n        Path(cfg["memory"]["episodic_db"]).parent,\n        Path(cfg["memory"]["semantic_lance"]).parent,\n        Path(cfg["logging"]["dir"]),\n        Path(cfg["paths"]["state"]).parent,\n        Path(cfg["paths"]["snapshots"]),\n        Path(cfg["scores"]["drift"]["snapshot_dir"]),\n        ROOT_DIR / "memory" / "self_snapshots",\n        ROOT_DIR / "milestones",\n        ROOT_DIR / "sandbox",\n        ROOT_DIR / "data",  # NEW: for cognitive features\n    ]\n    for p in dirs:\n        p.mkdir(parents=True, exist_ok=True)\n    for key in ("inbox", "outbox"):\n        p = Path(cfg["paths"][key])\n        if not p.exists():\n            p.touch()\n\ndef is_first_run(cfg: dict) -> bool:\n    return not Path(cfg["paths"]["state"]).exists()\n\ndef bootstrap_from_seed(seed: dict, cfg: dict, logger: logging.Logger) -> None:\n    identity = seed.get("identity", {})\n    state = {\n        "name":           identity.get("name", "Digital Being"),\n        "purpose":        identity.get("purpose", ""),\n        "scores":         seed.get("scores", {}),\n        "pending_tasks":  seed.get("first_instructions", []),\n        "anchor_values":  seed.get("anchor_values", {}),\n        "tick_count":     0,\n        "initialized_at": time.strftime("%Y-%m-%dT%H:%M:%S"),\n    }\n    state_path = Path(cfg["paths"]["state"])\n    state_path.parent.mkdir(parents=True, exist_ok=True)\n    with state_path.open("w", encoding="utf-8") as f:\n        json.dump(state, f, ensure_ascii=False, indent=2)\n    logger.info(f"First run: state bootstrapped as '{state['name']}' .")\n\ndef make_memory_handlers(mem: EpisodicMemory, logger: logging.Logger) -> dict:\n    async def on_user_message(data: dict) -> None:\n        text = data.get("text", "")\n        logger.info(f"[EVENT] user.message ‚Üí '{text[:120]}'" )\n        mem.add_episode("user.message", text[:_MAX_DESC_LEN] or "(empty)", data={"tick": data.get("tick")})\n    async def on_user_urgent(data: dict) -> None:\n        text = data.get("text", "")\n        logger.warning(f"[EVENT] user.urgent ‚ö° ‚Üí '{text[:120]}'")\n        mem.add_episode("urgent", text[:_MAX_DESC_LEN] or "(empty)", data={"tick": data.get("tick")})\n    async def on_file_changed(data: dict) -> None:\n        mem.add_episode("world.file_changed", f"File modified: {data.get('path','?')}")\n    async def on_file_created(data: dict) -> None:\n        mem.add_episode("world.file_created", f"File created: {data.get('path','?')}")\n    async def on_file_deleted(data: dict) -> None:\n        mem.add_episode("world.file_deleted", f"File deleted: {data.get('path','?')}")\n    return {\n        "user.message": on_user_message, "user.urgent": on_user_urgent,\n        "world.file_changed": on_file_changed, "world.file_created": on_file_created,\n        "world.file_deleted": on_file_deleted,\n    }\n\ndef make_world_handlers(logger: logging.Logger) -> dict:\n    async def on_world_ready(data: dict) -> None:\n        logger.info(f"[WorldModel] Ready. Indexed {data.get('file_count', '?')} files.")\n    async def on_world_updated(data: dict) -> None:\n        logger.debug(f"[WorldModel] Updated: {data.get('summary', '')}")\n    return {"world.ready": on_world_ready, "world.updated": on_world_updated}\n\ndef make_value_handlers(values: ValueEngine, mem: EpisodicMemory, logger: logging.Logger) -> dict:\n    async def on_value_changed(data: dict) -> None:\n        logger.info(f"[ValueEngine] {data.get('context', '')}")\n        for w in values.check_drift():\n            mem.add_episode("value.drift_warning", w[:_MAX_DESC_LEN])\n    return {"value.changed": on_value_changed}\n\ndef make_self_handlers(self_model: SelfModel, mem: EpisodicMemory, logger: logging.Logger) -> dict:\n    async def on_self_drift_detected(data: dict) -> None:\n        msg = f"Self drift: v{data.get('past_version')} ‚Üí v{data.get('current_version')} (Œî{data.get('delta')})"\n        logger.warning(f"[SelfModel] {msg}")\n        mem.add_episode("self.drift_detected", msg[:_MAX_DESC_LEN])\n    return {"self.drift_detected": on_self_drift_detected}\n\ndef make_strategy_handlers(milestones: Milestones, mem: EpisodicMemory, logger: logging.Logger) -> dict:\n    async def on_vector_changed(data: dict) -> None:\n        vector = data.get("vector", "")\n        logger.info(f"[StrategyEngine] Long-term vector changed: '{vector[:120]}'")\n        milestones.achieve("first_vector_change", f"–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –∏–∑–º–µ–Ω—ë–Ω: '{vector[:80]}'")\n        mem.add_episode("strategy.vector_changed", f"–ù–æ–≤—ã–π –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–π –≤–µ–∫—Ç–æ—Ä: '{vector[:200]}'", outcome="success")\n    return {"strategy.vector_changed": on_vector_changed}\n\ndef make_dream_handlers(mem: EpisodicMemory, logger: logging.Logger) -> dict:\n    async def on_dream_completed(data: dict) -> None:\n        logger.info(f"[DreamMode] Completed. insights={data.get('insights_count', 0)} vector_updated={data.get('vector_updated', False)} principle_added={data.get('principle_added', False)} run_count={data.get('run_count', '?')}")\n        mem.add_episode("dream.completed", f"–¶–∏–∫–ª –º–µ—á—Ç–∞–Ω–∏–π –∑–∞–≤–µ—Ä—à—ë–Ω. –ò–Ω—Å–∞–π—Ç–æ–≤: {data.get('insights_count', 0)}, –≤–µ–∫—Ç–æ—Ä –æ–±–Ω–æ–≤–ª—ë–Ω: {data.get('vector_updated', False)}", outcome="success")\n    return {"dream.completed": on_dream_completed}\n\ndef make_reflection_handlers(mem: EpisodicMemory, logger: logging.Logger) -> dict:\n    async def on_reflection_completed(data: dict) -> None:\n        tick = data.get("tick", "?")\n        contradictions = data.get("contradictions", 0)\n        logger.info(f"[ReflectionEngine] Reflection completed at tick #{tick}. contradictions={contradictions}")\n    return {"reflection.completed": on_reflection_completed}\n\ndef make_narrative_handlers(mem: EpisodicMemory, logger: logging.Logger) -> dict:\n    async def on_narrative_entry_written(data: dict) -> None:\n        tick = data.get("tick", "?")\n        logger.info(f"[NarrativeEngine] Diary entry written at tick #{tick}.")\n    return {"narrative.entry_written": on_narrative_entry_written}\n\ndef make_self_modification_handlers(mem: EpisodicMemory, logger: logging.Logger) -> dict:\n    async def on_config_modified(data: dict) -> None:\n        key = data.get("key", "?")\n        new_value = data.get("new_value", "?")\n        old_value = data.get("old_value", "?")\n        logger.info(f"[SelfModification] Config changed: {key} = {new_value} (was {old_value})")\n    return {"config.modified": on_config_modified}\n\nasync def _dream_loop(dream: DreamMode, stop_event: asyncio.Event, logger: logging.Logger) -> None:\n    logger.info("DreamMode loop started.")\n    while not stop_event.is_set():\n        await asyncio.sleep(300)\n        if stop_event.is_set():\n            break\n        if dream.should_run():\n            logger.info("DreamMode: interval elapsed ‚Äî starting dream cycle.")\n            try:\n                loop = asyncio.get_event_loop()\n                result = await loop.run_in_executor(None, dream.run)\n                if result.get("skipped"):\n                    logger.info(f"DreamMode: skipped ({result.get('reason', '?')}).")\n            except Exception as e:\n                logger.error(f"DreamMode loop error: {e}")\n    logger.info("DreamMode loop stopped.")\n\n# NEW: Memory consolidation loop\nasync def _consolidation_loop(consolidator: MemoryConsolidation, stop_event: asyncio.Event, logger: logging.Logger) -> None:\n    logger.info("MemoryConsolidation loop started.")\n    while not stop_event.is_set():\n        await asyncio.sleep(3600)  # Check every hour\n        if stop_event.is_set():\n            break\n        if consolidator.should_consolidate():\n            logger.info("MemoryConsolidation: starting sleep cycle...")\n            try:\n                result = await consolidator.consolidate()\n                logger.info(f"MemoryConsolidation: {result}")\n            except Exception as e:\n                logger.error(f"MemoryConsolidation error: {e}")\n    logger.info("MemoryConsolidation loop stopped.")\n\n# NEW: Multi-agent message polling loop\nasync def _multi_agent_loop(coordinator: MultiAgentCoordinator, stop_event: asyncio.Event, logger: logging.Logger) -> None:\n    logger.info("ü§ù Multi-Agent message polling started.")\n    poll_interval = coordinator.config.get("message_processing", {}).get("poll_interval_sec", 2)\n    while not stop_event.is_set():\n        try:\n            messages = coordinator.check_messages()\n            if messages:\n                logger.debug(f"ü§ù Processed {len(messages)} messages from network")\n        except Exception as e:\n            logger.error(f"Multi-agent polling error: {e}")\n        await asyncio.sleep(poll_interval)\n    logger.info("ü§ù Multi-Agent loop stopped.")\n\nasync def async_main(cfg: dict, logger: logging.Logger) -> None:\n    loop = asyncio.get_running_loop()\n    state_path = Path(cfg["paths"]["state"])\n    log_dir = Path(cfg["logging"]["dir"])\n    start_time = time.time()\n\n    mem = EpisodicMemory(Path(cfg["memory"]["episodic_db"]))\n    mem.init()\n    if not mem.health_check():\n        logger.error("EpisodicMemory health check FAILED. Aborting.")\n        return\n    mem.add_episode("system.start", "Digital Being started with Multi-Agent support", outcome="success")\n\n    principles_stored = mem.get_active_principles()\n    if principles_stored:\n        for p in principles_stored:\n            logger.info(f"  ‚Ä¢ [{p['id']}] {p['text']}")\n\n    vector_mem = VectorMemory(ROOT_DIR / "memory" / "vector_memory.db")\n    vector_mem.init()\n    logger.info(f"VectorMemory ready. Stored vectors: {vector_mem.count()}")\n\n    bus = EventBus()\n    values = ValueEngine(cfg=cfg, bus=bus)\n    values.load(state_path=state_path, seed_path=SEED_PATH)\n    values.subscribe()\n    values.save_weekly_snapshot()\n\n    self_model = SelfModel(bus=bus)\n    self_model.load(self_model_path=ROOT_DIR / "self_model.json", seed_path=SEED_PATH, snapshots_dir=ROOT_DIR / "memory" / "self_snapshots")\n    self_model.subscribe()\n    self_model.save_weekly_snapshot()\n\n    milestones = Milestones(bus=bus)\n    milestones.load(ROOT_DIR / "milestones" / "milestones.json")\n    milestones.subscribe()\n\n    ollama = OllamaClient(cfg)\n    ollama_ok = ollama.is_available()\n    if ollama_ok:\n        logger.info("Ollama: ‚úÖ available")\n    else:\n        logger.warning("Ollama: ‚ùå unavailable. HeavyTick will skip ticks until Ollama comes up.")\n\n    for event_name, handler in make_memory_handlers(mem, logger).items():\n        bus.subscribe(event_name, handler)\n    for event_name, handler in make_world_handlers(logger).items():\n        bus.subscribe(event_name, handler)\n    for event_name, handler in make_value_handlers(values, mem, logger).items():\n        bus.subscribe(event_name, handler)\n    for event_name, handler in make_self_handlers(self_model, mem, logger).items():\n        bus.subscribe(event_name, handler)\n    for event_name, handler in make_dream_handlers(mem, logger).items():\n        bus.subscribe(event_name, handler)\n\n    world = WorldModel(bus=bus, mem=mem)\n    world.subscribe()\n\n    monitor = FileMonitor(watch_path=ROOT_DIR, bus=bus)\n    monitor.start(loop)\n\n    strategy = StrategyEngine(memory_dir=ROOT_DIR / "memory", event_bus=bus)\n    strategy.load()\n    for event_name, handler in make_strategy_handlers(milestones, mem, logger).items():\n        bus.subscribe(event_name, handler)\n\n    dream_cfg = cfg.get("dream", {})\n    dream_enabled = dream_cfg.get("enabled", True)\n    dream_interval = float(dream_cfg.get("interval_hours", 6))\n    dream = DreamMode(episodic=mem, vector_memory=vector_mem, strategy=strategy, values=values, self_model=self_model,\n                      ollama=ollama, event_bus=bus, memory_dir=ROOT_DIR / "memory", interval_hours=dream_interval)\n\n    emotion_engine = EmotionEngine(memory_dir=ROOT_DIR / "memory")\n    emotion_engine.load()\n    dominant_name, dominant_val = emotion_engine.get_dominant()\n    logger.info(f"EmotionEngine ready. Dominant: {dominant_name}({dominant_val:.2f}) | Tone: {emotion_engine.get_tone_modifier()}")\n\n    reflection_cfg = cfg.get("reflection", {})\n    reflection_every = int(reflection_cfg.get("every_n_ticks", 10))\n    reflection_engine = ReflectionEngine(episodic=mem, value_engine=values, self_model=self_model, emotion_engine=emotion_engine,\n                                         strategy_engine=strategy, ollama=ollama, event_bus=bus, memory_dir=ROOT_DIR / "memory",\n                                         every_n_ticks=reflection_every)\n    for event_name, handler in make_reflection_handlers(mem, logger).items():\n        bus.subscribe(event_name, handler)\n    logger.info(f"ReflectionEngine ready. Runs every {reflection_every} ticks.")\n\n    narrative_cfg = cfg.get("narrative", {})\n    narrative_every = int(narrative_cfg.get("every_n_ticks", 15))\n    narrative_engine = NarrativeEngine(episodic=mem, emotion_engine=emotion_engine, strategy_engine=strategy, self_model=self_model,\n                                       ollama=ollama, memory_dir=ROOT_DIR / "memory", every_n_ticks=narrative_every, event_bus=bus)\n    for event_name, handler in make_narrative_handlers(mem, logger).items():\n        bus.subscribe(event_name, handler)\n    logger.info(f"NarrativeEngine ready. Writes diary every {narrative_every} ticks.")\n\n    goal_persistence = GoalPersistence(memory_dir=ROOT_DIR / "memory")\n    goal_persistence.load()\n    if goal_persistence.was_interrupted():\n        ag = goal_persistence.get_active()\n        last_goal = ag.get("goal", "?") if ag else "?"\n        logger.warning(f"[GoalPersistence] System recovering from interruption. Last goal: '{last_goal[:120]}'")\n    else:\n        logger.info("[GoalPersistence] Clean start ‚Äî no interrupted goal.")\n\n    attention_system = AttentionSystem(memory_dir=ROOT_DIR / "memory", emotion_engine=emotion_engine, value_engine=values)\n    logger.info(f"AttentionSystem ready. Focus: {attention_system.get_focus_summary()}")\n\n    curiosity_cfg = cfg.get("curiosity", {})\n    curiosity_enabled = bool(curiosity_cfg.get("enabled", True))\n    curiosity_engine = CuriosityEngine(memory_dir=ROOT_DIR / "memory")\n    curiosity_engine.load()\n    cur_stats = curiosity_engine.get_stats()\n    logger.info(f"CuriosityEngine ready. open={cur_stats['open']} answered={cur_stats['answered']} total_asked={cur_stats['total_asked']}")\n\n    self_modification = SelfModificationEngine(config_path=CONFIG_PATH, memory_dir=ROOT_DIR / "memory", ollama=ollama, event_bus=bus)\n    for event_name, handler in make_self_modification_handlers(mem, logger).items():\n        bus.subscribe(event_name, handler)\n    mod_stats = self_modification.get_stats()\n    logger.info(f"SelfModificationEngine ready. applied={mod_stats['total_applied']} approved={mod_stats['approved']} rejected={mod_stats['rejected']}")\n\n    belief_system = BeliefSystem(state_path=ROOT_DIR / "memory" / "beliefs.json")\n    belief_stats = belief_system.get_stats()\n    logger.info(f"BeliefSystem ready. active={belief_stats['active']} strong={belief_stats['strong']} rejected={belief_stats['rejected']} total_formed={belief_stats['total_beliefs_formed']}")\n\n    contradiction_resolver = ContradictionResolver(state_path=ROOT_DIR / "memory" / "contradictions.json")\n    contr_stats = contradiction_resolver.get_stats()\n    logger.info(f"ContradictionResolver ready. pending={contr_stats['pending']} resolved={contr_stats['resolved']} total_detected={contr_stats['total_detected']}")\n\n    shell_cfg = cfg.get("shell", {})\n    shell_enabled = bool(shell_cfg.get("enabled", True))\n    shell_executor = None\n    if shell_enabled:\n        allowed_dir = Path(shell_cfg.get("allowed_dir", "."))\n        if not allowed_dir.is_absolute():\n            allowed_dir = ROOT_DIR / allowed_dir\n        max_output_chars = int(shell_cfg.get("max_output_chars", 2000))\n        shell_executor = ShellExecutor(allowed_dir=allowed_dir, memory_dir=ROOT_DIR / "memory", max_output_chars=max_output_chars)\n        shell_stats = shell_executor.get_stats()\n        logger.info(f"ShellExecutor ready. executed={shell_stats['total_executed']} rejected={shell_stats['total_rejected']} errors={shell_stats['total_errors']}")\n    else:\n        logger.info("ShellExecutor disabled.")\n\n    time_perc_cfg = cfg.get("time_perception", {})\n    time_perc_enabled = bool(time_perc_cfg.get("enabled", True))\n    time_perc = None\n    if time_perc_enabled:\n        time_perc = TimePerception(memory_dir=ROOT_DIR / "memory")\n        time_perc.load()\n        time_stats = time_perc.get_stats()\n        logger.info(f"TimePerception ready. patterns={time_stats['total_patterns']} time_of_day={time_stats['current_time_of_day']}")\n    else:\n        logger.info("TimePerception disabled.")\n\n    social_cfg = cfg.get("social", {})\n    social_enabled = bool(social_cfg.get("enabled", True))\n    social_layer = None\n    if social_enabled:\n        inbox_path = ROOT_DIR / cfg["paths"]["inbox"]\n        outbox_path = ROOT_DIR / cfg["paths"]["outbox"]\n        social_layer = SocialLayer(inbox_path=inbox_path, outbox_path=outbox_path, memory_dir=ROOT_DIR / "memory")\n        social_layer.load()\n        social_stats = social_layer.get_stats()\n        logger.info(f"SocialLayer ready. incoming={social_stats['total_incoming']} outgoing={social_stats['total_outgoing']} pending={social_stats['pending_response']}")\n    else:\n        logger.info("SocialLayer disabled.")\n\n    meta_cog_cfg = cfg.get("meta_cognition", {})\n    meta_cog_enabled = bool(meta_cog_cfg.get("enabled", True))\n    meta_cog = None\n    if meta_cog_enabled:\n        meta_cog = MetaCognition(memory_dir=ROOT_DIR / "memory", config=meta_cog_cfg)\n        meta_cog.load()\n        meta_stats = meta_cog.get_stats()\n        logger.info(f"MetaCognition ready. insights={meta_stats['total_insights']} decisions_logged={meta_stats['total_decisions_logged']} calibration={meta_stats['calibration_score']:.2f}")\n    else:\n        logger.info("MetaCognition disabled.")\n\n    # ============================================================\n    # NEW: 8-Layer Cognitive Architecture + Stage 26\n    # ============================================================\n    \n    # Layer 2: Tool Registry\n    tool_registry = ToolRegistry()\n    initialize_default_tools(tool_registry, allowed_dirs=[ROOT_DIR / "sandbox", ROOT_DIR / "data"])\n    tool_stats = tool_registry.get_statistics()\n    logger.info(f"üõ†Ô∏è  ToolRegistry ready. tools={tool_stats['total_tools']} executions={tool_stats.get('total_executions', 0)}")\n    \n    # Layer 3: Continuous Learning\n    learning_engine = LearningEngine(\n        memory=mem,\n        storage_path=ROOT_DIR / "data" / "learning_patterns.json"\n    )\n    learning_stats = learning_engine.get_statistics()\n    logger.info(f"üß† LearningEngine ready. patterns={learning_stats.get('total_patterns', 0)}")\n    \n    # NEW: Stage 26 - Skill Library\n    skill_cfg = cfg.get("skills", {})\n    skill_enabled = bool(skill_cfg.get("enabled", True))\n    skill_library = None\n    if skill_enabled:\n        skill_library = SkillLibrary(memory_dir=ROOT_DIR / "memory", ollama=ollama)\n        skill_library.load()\n        skill_stats = skill_library.get_stats()\n        logger.info(f"üìö SkillLibrary ready. skills={skill_stats['total_skills']} extractions={skill_stats['total_extractions']} uses={skill_stats['total_skill_uses']}")\n    else:\n        logger.info("üìö SkillLibrary disabled.")\n    \n    # NEW: Stage 27 - Multi-Agent Communication\n    multi_agent_cfg = cfg.get("multi_agent", {})\n    multi_agent_enabled = bool(multi_agent_cfg.get("enabled", False))\n    multi_agent_coordinator = None\n    if multi_agent_enabled and skill_library:\n        agent_id = f"{multi_agent_cfg.get('agent_name', 'primary')}_{int(time.time())}"\n        storage_dir = ROOT_DIR / "memory"\n        # Ensure shared storage directories exist\n        shared_registry = Path(multi_agent_cfg.get("shared_storage", {}).get("registry_path", "memory/multi_agent/shared_registry.json"))\n        shared_messages = Path(multi_agent_cfg.get("shared_storage", {}).get("message_storage", "memory/multi_agent/shared_messages"))\n        if not shared_registry.is_absolute():\n            shared_registry = ROOT_DIR / shared_registry\n        if not shared_messages.is_absolute():\n            shared_messages = ROOT_DIR / shared_messages\n        shared_registry.parent.mkdir(parents=True, exist_ok=True)\n        shared_messages.mkdir(parents=True, exist_ok=True)\n        \n        multi_agent_coordinator = MultiAgentCoordinator(\n            agent_id=agent_id,\n            agent_name=multi_agent_cfg.get("agent_name", "primary"),\n            specialization=multi_agent_cfg.get("specialization", "general"),\n            skill_library=skill_library,\n            config=multi_agent_cfg,\n            storage_dir=storage_dir,\n        )\n        if multi_agent_cfg.get("auto_register", True):\n            multi_agent_coordinator.register()\n        ma_stats = multi_agent_coordinator.get_stats()\n        logger.info(f"ü§ù MultiAgentCoordinator ready. agent_id={agent_id[:20]}... online_agents={ma_stats['registry']['online_agents']}")\n    elif multi_agent_enabled and not skill_library:\n        logger.warning("ü§ù MultiAgent requires SkillLibrary. Enable skills to use multi-agent features.")\n    else:\n        logger.info("ü§ù MultiAgentCoordinator disabled.")\n    \n    # Layer 4: Memory Consolidation\n    consolidation_cfg = cfg.get("consolidation", {})\n    consolidation_enabled = bool(consolidation_cfg.get("enabled", True))\n    consolidator = None\n    if consolidation_enabled:\n        consolidator = MemoryConsolidation(\n            memory=mem,\n            ollama=ollama,\n            beliefs=belief_system,\n            consolidation_interval=int(consolidation_cfg.get("interval_hours", 24)) * 3600\n        )\n        consol_stats = consolidator.get_statistics()\n        logger.info(f"üí§ MemoryConsolidation ready. consolidations={consol_stats['total_consolidations']}")\n    else:\n        logger.info("üí§ MemoryConsolidation disabled.")\n    \n    # Layer 5: Theory of Mind (User Model)\n    user_model_cfg = cfg.get("user_model", {})\n    user_model_enabled = bool(user_model_cfg.get("enabled", True))\n    user_model = None\n    if user_model_enabled:\n        user_model = UserModel(storage_path=ROOT_DIR / "data" / "user_model.json")\n        logger.info(f"üß† UserModel ready. interactions={user_model._interaction_count}")\n    else:\n        logger.info("üß† UserModel disabled.")\n    \n    # Layer 7: Proactive Behavior\n    proactive_cfg = cfg.get("proactive", {})\n    proactive_enabled = bool(proactive_cfg.get("enabled", True))\n    proactive = None\n    if proactive_enabled and user_model:\n        proactive = ProactiveBehaviorEngine(user_model=user_model, memory=mem)\n        proactive_stats = proactive.get_statistics()\n        logger.info(f"üöÄ ProactiveBehavior ready. triggers={len(proactive._triggers)}")\n    else:\n        logger.info("üöÄ ProactiveBehavior disabled.")\n    \n    # Layer 8: Meta-Learning\n    meta_learn_cfg = cfg.get("meta_learning", {})\n    meta_learn_enabled = bool(meta_learn_cfg.get("enabled", True))\n    meta_optimizer = None\n    if meta_learn_enabled:\n        meta_optimizer = MetaOptimizer(storage_path=ROOT_DIR / "data" / "meta_learning.json")\n        logger.info(f"üî¨ MetaOptimizer ready. tests={len(meta_optimizer._ab_tests)}")\n    else:\n        logger.info("üî¨ MetaOptimizer disabled.")\n    \n    # Layer 1: Goal-Oriented Behavior (integrates with heavy tick)\n    goal_oriented = GoalOrientedBehavior(\n        ollama=ollama,\n        world=world,\n        memory=mem,\n        storage_dir=ROOT_DIR / "memory",\n        shell_executor=shell_executor,\n    )\n    logger.info(f"üéØ GoalOrientedBehavior ready.")\n    \n    # Layer 0: Fault-Tolerant HeavyTick\n    heavy = FaultTolerantHeavyTick(\n        cfg=cfg,\n        ollama=ollama,\n        world=world,\n        values=values,\n        self_model=self_model,\n        mem=mem,\n        milestones=milestones,\n        log_dir=log_dir,\n        sandbox_dir=ROOT_DIR / "sandbox",\n        strategy=strategy,\n        vector_memory=vector_mem,\n        emotion_engine=emotion_engine,\n        reflection_engine=reflection_engine,\n        narrative_engine=narrative_engine,\n        goal_persistence=goal_persistence,\n        attention_system=attention_system,\n        curiosity_engine=curiosity_engine if curiosity_enabled else None,\n        self_modification=self_modification,\n        belief_system=belief_system,\n        contradiction_resolver=contradiction_resolver,\n        shell_executor=shell_executor,\n        time_perception=time_perc,\n        social_layer=social_layer,\n        meta_cognition=meta_cog,\n        # NEW: Cognitive architecture components\n        goal_oriented=goal_oriented,\n        tool_registry=tool_registry,\n        learning_engine=learning_engine,\n        skill_library=skill_library,\n        user_model=user_model,\n        proactive=proactive,\n        meta_optimizer=meta_optimizer,\n        multi_agent_coordinator=multi_agent_coordinator,  # NEW: Stage 27\n    )\n    logger.info("‚ö° FaultTolerantHeavyTick initialized with Multi-Agent support.")\n\n    ticker = LightTick(cfg=cfg, bus=bus)\n\n    api_cfg = cfg.get("api", {})\n    api_enabled = api_cfg.get("enabled", True)\n    api_components = {\n        "episodic": mem, "vector_memory": vector_mem, "value_engine": values, "strategy_engine": strategy,\n        "self_model": self_model, "milestones": milestones, "dream_mode": dream, "ollama": ollama,\n        "heavy_tick": heavy, "emotion_engine": emotion_engine, "reflection_engine": reflection_engine,\n        "narrative_engine": narrative_engine, "goal_persistence": goal_persistence, "attention_system": attention_system,\n        "curiosity_engine": curiosity_engine, "self_modification": self_modification,\n        "belief_system": belief_system, "contradiction_resolver": contradiction_resolver,\n        "shell_executor": shell_executor, "time_perception": time_perc, "social_layer": social_layer,\n        "meta_cognition": meta_cog,\n        # NEW components\n        "tool_registry": tool_registry,\n        "learning_engine": learning_engine,\n        "skill_library": skill_library,\n        "user_model": user_model,\n        "proactive": proactive,\n        "meta_optimizer": meta_optimizer,\n        "goal_oriented": goal_oriented,\n        "multi_agent_coordinator": multi_agent_coordinator,  # NEW: Stage 27\n    }\n    api = IntrospectionAPI(\n        host=api_cfg.get("host", "127.0.0.1"),\n        port=int(api_cfg.get("port", 8765)),\n        components=api_components,\n        start_time=start_time,\n    )\n    if api_enabled:\n        await api.start()\n\n    file_count = await world.scan(ROOT_DIR)\n    mem.add_episode("world.scan", f"Initial scan: {file_count} files", outcome="success", data={"file_count": file_count})\n\n    gp_stats = goal_persistence.get_stats()\n    logger.info("=" * 72)\n    logger.info(f"  World        : {world.summary()}")\n    logger.info(f"  Values       : {values.to_prompt_context()}")\n    logger.info(f"  Self v{self_model.get_version():<3}    : {self_model.get_identity()['name']}")\n    logger.info(f"  Principles   : {len(self_model.get_principles())}")\n    logger.info(f"  {milestones.summary()}")\n    logger.info(f"  Strategy     : {strategy.to_prompt_context()!r:.120}")\n    logger.info(f"  Vectors      : {vector_mem.count()} stored")\n    logger.info(f"  DreamMode    : {'enabled' if dream_enabled else 'disabled'}, interval={dream_interval}h")\n    logger.info(f"  EmotionEngine: dominant={dominant_name}({dominant_val:.2f})")\n    logger.info(f"  Reflection   : every {reflection_every} ticks")\n    logger.info(f"  Narrative    : every {narrative_every} ticks")\n    logger.info(f"  GoalPersist  : completed={gp_stats['total_completed']} resumes={gp_stats['resume_count']} interrupted={gp_stats['interrupted']}")\n    logger.info(f"  Attention    : {attention_system.get_focus_summary()}")\n    logger.info(f"  Curiosity    : {'enabled' if curiosity_enabled else 'disabled'} open={cur_stats['open']} total_asked={cur_stats['total_asked']}")\n    logger.info(f"  SelfMod      : applied={mod_stats['total_applied']} approved={mod_stats['approved']} rejected={mod_stats['rejected']}")\n    logger.info(f"  Beliefs      : active={belief_stats['active']} strong={belief_stats['strong']} rejected={belief_stats['rejected']}")\n    logger.info(f"  Contradictns : pending={contr_stats['pending']} resolved={contr_stats['resolved']}")\n    if shell_executor:\n        shell_stats = shell_executor.get_stats()\n        logger.info(f"  ShellExec    : executed={shell_stats['total_executed']} rejected={shell_stats['total_rejected']}")\n    if time_perc:\n        time_stats = time_perc.get_stats()\n        logger.info(f"  TimePerc     : patterns={time_stats['total_patterns']} time={time_stats['current_time_of_day']}")\n    if social_layer:\n        social_stats = social_layer.get_stats()\n        logger.info(f"  SocialLayer  : incoming={social_stats['total_incoming']} outgoing={social_stats['total_outgoing']}")\n    if meta_cog:\n        meta_stats = meta_cog.get_stats()\n        logger.info(f"  MetaCog      : insights={meta_stats['total_insights']} calibration={meta_stats['calibration_score']:.2f}")\n    # NEW architecture stats\n    logger.info(f"  üõ†Ô∏è  Tools       : {tool_stats['total_tools']} registered")\n    logger.info(f"  üß† Learning    : {learning_stats.get('total_patterns', 0)} patterns")\n    if skill_library:\n        logger.info(f"  üìö Skills      : {skill_stats['total_skills']} skills, {skill_stats['total_skill_uses']} uses")\n    if multi_agent_coordinator:\n        logger.info(f"  ü§ù MultiAgent  : {ma_stats['registry']['online_agents']} agents online")\n    if consolidator:\n        logger.info(f"  üí§ Consolidatn : {'enabled' if consolidation_enabled else 'disabled'}")\n    if user_model:\n        logger.info(f"  üß† UserModel   : {user_model._interaction_count} interactions")\n    if proactive:\n        logger.info(f"  üöÄ Proactive   : {len(proactive._triggers)} triggers")\n    if meta_optimizer:\n        logger.info(f"  üî¨ MetaLearn   : {len(meta_optimizer._ab_tests)} A/B tests")\n    logger.info(f"  API          : {'http://' + api_cfg.get('host','127.0.0.1') + ':' + str(api_cfg.get('port',8765)) if api_enabled else 'disabled'}")\n    logger.info(f"  Ollama       : {'ok' if ollama_ok else 'unavailable'}")\n    logger.info("=" * 72)\n    logger.info("üß† 8-Layer Cognitive Architecture + Stage 27 Multi-Agent ACTIVE")\n    logger.info("Running... (Ctrl+C to stop)")\n\n    stop_event = asyncio.Event()\n    def _signal_handler():\n        logger.info("Shutdown signal received.")\n        stop_event.set()\n    for sig in (signal.SIGINT, signal.SIGTERM):\n        try:\n            loop.add_signal_handler(sig, _signal_handler)\n        except NotImplementedError:\n            signal.signal(sig, lambda s, f: stop_event.set())\n\n    light_task = asyncio.create_task(ticker.start(), name="light_tick")\n    heavy_task = asyncio.create_task(heavy.start(), name="heavy_tick")\n    dream_task = asyncio.create_task(_dream_loop(dream, stop_event, logger), name="dream_loop") if dream_enabled else None\n    consolidation_task = asyncio.create_task(_consolidation_loop(consolidator, stop_event, logger), name="consolidation_loop") if (consolidation_enabled and consolidator) else None\n    multi_agent_task = asyncio.create_task(_multi_agent_loop(multi_agent_coordinator, stop_event, logger), name="multi_agent_loop") if multi_agent_enabled and multi_agent_coordinator else None\n\n    await stop_event.wait()\n\n    goal_persistence.mark_interrupted()\n    ticker.stop()\n    heavy.stop()\n    monitor.stop()\n    if api_enabled:\n        await api.stop()\n\n    tasks_to_cancel = [light_task, heavy_task]\n    if dream_task is not None:\n        tasks_to_cancel.append(dream_task)\n    if consolidation_task is not None:\n        tasks_to_cancel.append(consolidation_task)\n    if multi_agent_task is not None:\n        tasks_to_cancel.append(multi_agent_task)\n    for task in tasks_to_cancel:\n        task.cancel()\n        try:\n            await task\n        except asyncio.CancelledError:\n            pass\n\n    values.save_weekly_snapshot()\n    self_model.save_weekly_snapshot()\n    await self_model.check_drift(values)\n    \n    # Save new components\n    if learning_engine:\n        learning_engine.save()\n    if user_model:\n        user_model.save()\n    if meta_optimizer:\n        meta_optimizer.save()\n    if skill_library:\n        skill_library.save()\n\n    mem.add_episode("system.stop", "Digital Being stopped cleanly", outcome="success")\n    vector_mem.close()\n    mem.close()\n    logger.info("Digital Being shut down cleanly.")\n\ndef main() -> None:\n    cfg = load_yaml(CONFIG_PATH)\n    seed = load_yaml(SEED_PATH)\n    logger = setup_logging(cfg)\n    logger.info("=" * 60)\n    logger.info("  üß† Digital Being ‚Äî Stage 27.5: Multi-Agent Integration")\n    logger.info(f"  Version        : {cfg['system']['version']}")\n    logger.info(f"  Strategy model : {cfg['ollama']['strategy_model']}")\n    logger.info(f"  Embed model    : {cfg['ollama']['embed_model']}")\n    logger.info("=" * 60)\n    ensure_directories(cfg)\n    if is_first_run(cfg):\n        bootstrap_from_seed(seed, cfg, logger)\n    else:\n        logger.info("Existing state found. Resuming from memory/state.json.")\n    anchors = seed.get("anchor_values", {})\n    if anchors.get("locked"):\n        logger.info(f"Anchor values LOCKED ({len(anchors.get('values', []))} rules).")\n    asyncio.run(async_main(cfg, logger))\n\nif __name__ == "__main__":\n    main()\n